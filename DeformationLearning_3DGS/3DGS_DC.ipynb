{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deformation components of 3DGS\n",
    "- conda env: 3dgs+3dsrf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load output of 3DGS (class GaussianProp)\n",
    "- path to `../../gaussian_splatting/output/f336a291-bnotALLcam`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import h5py\n",
    "from scene import Scene, GaussianModel\n",
    "import numpy as np\n",
    "from utils.sh_utils import clamp_sh2rgb\n",
    "\n",
    "path_to_3dsrf = os.path.join(os.getcwd(), os.pardir, \"3DSSL-WS23_IntuitiveAnimation\")\n",
    "assert os.path.exists(path_to_3dsrf)\n",
    "sys.path.append(path_to_3dsrf)\n",
    "from utils.gaussian_utils import GaussianProp\n",
    "from utils.Dataset_handler import Filehandler\n",
    "from utils.pickel_io import load_from_memory\n",
    "from utils.OBJ_helper import OBJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO] set the path to output\n",
    "path_to_output = os.path.join(\"/mnt/hdd/----\")\n",
    "assert os.path.exists(path_to_output)\n",
    "\n",
    "# [TODO] set the session id\n",
    "session = \"f336a291-bnotALLcam\"\n",
    "path_to_session = os.path.join(path_to_output, session)\n",
    "assert os.path.exists(path_to_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_expNames, list_expPaths = Filehandler.dirwalker_InFolder(path_to_folder=path_to_session, prefix=\"E0\")\n",
    "print(\"the number of expressions: \", len(list_expNames))\n",
    "max_iter = 10_000\n",
    "\n",
    "GPs=[]\n",
    "\n",
    "for i, (expName, expPath) in enumerate(zip(list_expNames, list_expPaths)):\n",
    "    list_frames, list_framePaths = Filehandler.dirwalker_InFolder(path_to_folder=expPath, prefix=\"\")\n",
    "    # print(list_frames)\n",
    "    for frame, frame_path in zip(list_frames, list_framePaths):\n",
    "        path_to_PC = os.path.join(frame_path, \"point_cloud\")\n",
    "        path_to_maxIter = os.path.join(path_to_PC, \"iteration_\"+str(max_iter))\n",
    "        assert os.path.exists(path_to_PC) and os.path.exists(path_to_maxIter)\n",
    "        gp = load_from_memory(path_to_memory=os.path.join(path_to_maxIter, \"memory\"), pickle_fname=\"gaussian_prop.pkl\")\n",
    "        # print(gp)\n",
    "        GPs.append(gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian properties\n",
    "\n",
    "\n",
    "                @dataclass\n",
    "                class GaussianProp:\n",
    "                        xyz: np.ndarray\n",
    "                        normals: np.ndarray\n",
    "                        f_dc: np.ndarray #this is SH_coeffs, needs to be converted to RGB by SH2RGB\n",
    "                        f_rest: np.ndarray\n",
    "                        opacities: np.ndarray\n",
    "                        scale: np.ndarray\n",
    "                        rotation: np.ndarray\n",
    "                        covariance: np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveHDF5_GaussianProp(GPs, name_hdf5):\n",
    "    xyzs = []\n",
    "    normals = []\n",
    "    rgbs = []\n",
    "    f_dcs = []\n",
    "    f_rest = []\n",
    "    opacities = []\n",
    "    scales = []\n",
    "    rotations = []\n",
    "\n",
    "    # verts 87652\n",
    "    for i, gp in enumerate(GPs):\n",
    "        xyzs.append(gp.xyz.flatten())\n",
    "        normals.append(gp.normals.flatten())\n",
    "        rgbs.append(clamp_sh2rgb(gp.f_dc).flatten())\n",
    "        f_dcs.append(gp.f_dc.flatten())\n",
    "        f_rest.append(gp.f_rest.flatten())\n",
    "        opacities.append(gp.opacities.flatten())\n",
    "        scales.append(gp.scale.flatten())\n",
    "        rotations.append(gp.rotation.flatten())\n",
    "\n",
    "\n",
    "    path_to_dump = os.path.join(os.getcwd(), \"output\", session)\n",
    "    assert os.path.exists(path_to_dump)\n",
    "    with h5py.File(os.path.join(path_to_dump, name_hdf5), \"w\") as f:\n",
    "        dset = f.create_dataset(name = \"xyz\", data = xyzs)\n",
    "        dset = f.create_dataset(name=\"normal\", data = normals)\n",
    "        dset = f.create_dataset(name = \"rgb\", data = rgbs)\n",
    "        dset = f.create_dataset(name = \"f_dc\", data = f_dcs)\n",
    "        dset = f.create_dataset(name = \"f_rest\", data = f_rest)\n",
    "        dset = f.create_dataset(name = \"opacity\", data=opacities)\n",
    "        dset = f.create_dataset(name = \"scale\", data = scales)\n",
    "        dset = f.create_dataset(name = \"rotation\", data = rotations)\n",
    "    \n",
    "    print(f\"save hdf5 at {os.path.join(path_to_dump, name_hdf5)}\")\n",
    "\n",
    "    xyzs = np.asarray(xyzs)\n",
    "    print(f\"xyz shape: {xyzs.shape}\")\n",
    "    normals = np.asarray(normals)\n",
    "    print(f\"normals shape: {normals.shape}\")\n",
    "    rgbs = np.asarray(rgbs)\n",
    "    print(f\"rgbs shape: {rgbs.shape}\")\n",
    "    f_dcs = np.asarray(f_dcs)\n",
    "    print(f\"f_dcs shape: {f_dcs.shape}\")\n",
    "    f_rest = np.asarray(f_rest)\n",
    "    print(f\"f_rest shape: {f_rest.shape}\")\n",
    "    opacities = np.asarray(opacities)\n",
    "    print(f\"opacities shape: {opacities.shape}\")\n",
    "    scales = np.asarray(scales)\n",
    "    print(f\"scales shape: {scales.shape}\")\n",
    "    rotations = np.asarray(rotations)\n",
    "    print(f\"rotation shape: {rotations.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save GaussianProp in .hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveHDF5_GaussianProp(GPs=GPs, name_hdf5=session+\"_datamat_87652.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampling trained 3D Gaussians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of Gaussians = 5509\n",
    "- This is equivalent to 2x de-subdivision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveHDF5_GaussianProp(GPs=GPs, name_hdf5=session+\"_datamat_5509.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of Gaussians = 21954\n",
    "- This is equivalent to 1x de-subdivision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveHDF5_GaussianProp(GPs=GPs, name_hdf5=session+\"_datamat_21954.hdf5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dgs+3dsrf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
