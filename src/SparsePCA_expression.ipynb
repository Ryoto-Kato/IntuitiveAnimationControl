{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# get current date and year\n",
    "now = datetime.now()\n",
    "\n",
    "date = now.strftime(\"%d\") + now.strftime(\"%m\") + now.strftime(\"%Y\")\n",
    "print(date)\n",
    "time = now.strftime(\"%H_%M\")\n",
    "print(\"time:\", time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse components (sparse dictionary) analysis on multiple expressions meshes\n",
    "## Methods\n",
    "    - Sparse PCA\n",
    "    - MiniBatchSparsePCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n",
    "- READ OBJs systematically\n",
    "    - Make them functions to be called later\n",
    "- Perform different components analysis methods\n",
    "    - Select method\n",
    "    - Take into account only vertices which represebts the front face region which effectively used for facial expressions\n",
    "- Save in .pkl (which contains datastruct_blendshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## requirements/test-environment\n",
    "- Manjaro Linux\n",
    "- python 3.12.0\n",
    "- Anaconda 22.9.0\n",
    "    - packages-list\n",
    "        - see requirement.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read OBJs\n",
    "- place downloaded tracked meshes of multiple expressions /dataset/multiface/tracked_mesh/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# set path to dataset\n",
    "path_to_dataset = os.path.join(os.getcwd(), '../dataset/multiface/tracked_mesh/')\n",
    "save_path = \"../dataset/multiface/tracked_mesh\"\n",
    "\n",
    "ID = 6795937"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of expressions\n",
    "list_exps_name = []\n",
    "map_exps2id = {}\n",
    "counter = 0\n",
    "for i, name in enumerate(os.listdir(path_to_dataset)):\n",
    "    f = os.path.join(path_to_dataset, name)\n",
    "    if os.path.isdir(f) and name.startswith('E0'):\n",
    "        counter = counter + 1\n",
    "        list_exps_name.append(name)\n",
    "\n",
    "\n",
    "list_exps_name.sort()\n",
    "\n",
    "for i, exp_name in enumerate(list_exps_name):\n",
    "    print(f'{i}, {exp_name}')\n",
    "    map_exps2id.update({exp_name: i})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read OBJ in ./dataset/multiface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of expressions\n",
    "print(list_exps_name)\n",
    "print(map_exps2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File handler for .obj in ./utils/FolderHandler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Dataset_handler import Filehandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_handler = Filehandler(path_to_dataset=path_to_dataset)\n",
    "print(file_handler.get_path_to_dataset())\n",
    "file_handler.iter_dir()\n",
    "print(\"Expressions: Number of tracked mesh\")\n",
    "for key in file_handler.dict_objs.keys():\n",
    "    print(f'{list_exps_name[key]}: {len(file_handler.dict_objs[key])}')\n",
    "    print(file_handler.dict_objs[key]) \n",
    "# print(file_handler.dict_objs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBJ class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.OBJ_helper import OBJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test .obj loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"../dataset/multiface/tracked_mesh/E003_Neutral_Eyes_Closed/000783.obj\"\n",
    "test_obj = OBJ(test_path, swapyz=False)\n",
    "print(f'Number of vertices: {len(test_obj.vertices)}')\n",
    "print(test_obj.vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load all .obj in the certain directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_expOBJs = {}\n",
    "dict_expVerts = {}\n",
    "\n",
    "# select number of samples for a expression \n",
    "num_samples_perExp = 20\n",
    "\n",
    "for expID, key in enumerate(file_handler.dict_objs.keys()):\n",
    "    list_OBJs = []\n",
    "    list_Verts = []\n",
    "\n",
    "    # since there are many sequences for a expression, we assume that second half of tracked mesh in a sequence captured the specific expressions\n",
    "    # We only use second half of sequence for a expression.\n",
    "    # This is also for resonable memory usage as well. if you run over all, you will consume more than 30GB memory to store all of objects\n",
    "\n",
    "    # half_id = int(len(file_handler.dict_objs[key])/2)\n",
    "    # end_id = int(len(file_handler.dict_objs[key]))\n",
    "\n",
    "    for i, obj in enumerate(file_handler.dict_objs[key][0:num_samples_perExp]):\n",
    "        path_to_obj = os.path.join(file_handler.list_expPathFiles[expID], obj)\n",
    "        # print(path_to_obj)\n",
    "        obj = OBJ(path_to_obj, swapyz=False)\n",
    "        list_OBJs.append(obj)\n",
    "        list_Verts.append(obj.vertices)\n",
    "    dict_expOBJs.update({expID: list_OBJs})\n",
    "    dict_expVerts.update({expID: list_Verts})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the number of objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in dict_expVerts.keys():\n",
    "#     vertices = dict_expVerts[key]\n",
    "#     print(len(vertices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test conversion from list to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp0_vertices = dict_expVerts[0]\n",
    "print(f\"Expression: {list_exps_name[0]}\")\n",
    "print(f\"The number of meshes: {len(exp0_vertices)}\")\n",
    "print(f\"The number of vertices for each mesh: {len(exp0_vertices[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "num_vertices = 7306\n",
    "len_col = num_vertices*3\n",
    "print(f\"The number of vertices for each meesh: {num_vertices}\")\n",
    "print(f\"The number of columns of matrix X: {len_col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test concatenation and check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_np_array = np.array(exp0_vertices)\n",
    "print(_np_array.shape)\n",
    "print(_np_array[0][0][0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_array = np.array(exp0_vertices).reshape((_np_array.shape[0], len_col))\n",
    "print(_array.shape)\n",
    "print(_array[0][0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenation of vertex positions for all tracked meshes of 5 expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_list_xs = []\n",
    "num_sum_samples = 0\n",
    "for key in dict_expVerts.keys():\n",
    "    # exclulde  Neutral Eyes Open (Since it could be similar to averafe face of target person)\n",
    "    vertices = dict_expVerts[key]\n",
    "    _num_samples = len(vertices)\n",
    "    print(_num_samples)\n",
    "    num_sum_samples = num_sum_samples + _num_samples\n",
    "    _array = np.array(vertices).reshape((_num_samples, len_col))\n",
    "    _list_xs.append(_array)\n",
    "\n",
    "# print(f\"Len of _list_xs: {len(_list_xs)}\")\n",
    "# print(f\"The number of samples: {num_sum_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutralmesh_verts = _list_xs[0]\n",
    "X = _list_xs[0]\n",
    "for x in _list_xs[1:]:\n",
    "    X = np.concatenate((X, x), axis = 0)\n",
    "    # print(X)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the mean vertex coordinates over the sequence in \"E001_Neutral_Eyes_Opens\"\n",
    "- We assume that the average vertex coordinate over the sequence in \"E001_Neutral_Eyes_Open\" defines the ID's neutral face mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_neutralmesh_vertices = np.mean(neutralmesh_verts, axis = 0)\n",
    "print(ave_neutralmesh_vertices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For PCA, we need to centrailzed data at the neutral face which is defined like above not at the average expression\n",
    "- We need to subtract the matrix from the average vertex coordinates of the sequence of neutral face (\"E001_Neutral_Eyes_Opened\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cent_X = X-ave_neutralmesh_vertices[None, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the contents in matrix X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(X)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face mask\n",
    "- Masking the vertices to take into account only vertices composing the front face as you see below in blue\n",
    "\n",
    "- To do it, we only perform over these blue vertices.\n",
    "![face_mask_region](../images/Facemask_side01.png)\n",
    "\n",
    "- Approach\n",
    "    - In the data matrix, we replace vertices coordinate with 0 over the vertices composing other region "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Blendshape import FaceMask\n",
    "from utils.pickel_io import dump_pckl, load_from_memory\n",
    "\n",
    "# set the name of pickel file to be loaded\n",
    "pickel_fname = \"FaceMask_30102023_09_40.pkl\"\n",
    "\n",
    "facemask = load_from_memory(path_to_memory = save_path, pickle_fname = pickel_fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_cent_X = cent_X * facemask.bit_mask[None, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dump data matrix with mean (average neutral face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the data matrix if you need to dump the matrix to save loading time\n",
    "from utils.Blendshape import ZeroMeanDefMatrix\n",
    "deformation_data = ZeroMeanDefMatrix(masked_cent_x = masked_cent_X, mean = ave_neutralmesh_vertices)\n",
    "dd_pickel_fname = 'deformation_data_matrix_and_mean'+ '_' +date+'_'+time+'.pkl'\n",
    "dump_pckl(data = deformation_data, save_root= save_path, pickel_fname=dd_pickel_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the data matrix is masked\n",
    "# we chose the ID:3567 which is located on top of nose, this vertices should be masked with 1\n",
    "# as the center of facemesh which is obtained by the nearest neighboring search at the vertex\n",
    "\n",
    "print(sum(masked_cent_X[:,3567*3]) != 0)\n",
    "print(sum(masked_cent_X[:,3567*3+1]) != 0)\n",
    "print(sum(masked_cent_X[:,3567*3+2]) != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Analysis on tracked meshes\n",
    "- Select method from below\n",
    "    - SparsePCA\n",
    "    - MiniBatchSparsePCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_method = 'SparsePCA'\n",
    "name_method = 'MiniBatchSparsePCA'\n",
    "ESTIMATOR = None\n",
    "\n",
    "# number of components\n",
    "# if _n_components == None, the configuration of the number of components is by default\n",
    "_n_components = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# configure the esitimator as you need\n",
    "\n",
    "if name_method == 'SparsePCA':\n",
    "    try:\n",
    "        from sklearn.decomposition import SparsePCA\n",
    "        ESTIMATOR = SparsePCA(n_components = _n_components, max_iter = 100, verbose = True)\n",
    "    except ImportError:\n",
    "        print(\"Import Error: sklearn.decomposition.SparsePCA\")\n",
    "elif name_method == 'MiniBatchSparsePCA':\n",
    "    try:\n",
    "        from sklearn.decomposition import MiniBatchSparsePCA\n",
    "        ESTIMATOR = MiniBatchSparsePCA(n_components=_n_components, verbose = True)\n",
    "    except ImportError:\n",
    "        print(\"Import Error: sklearn.decomposition.MiniBatchSparsePCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the set of components\n",
    "- SparsePCA (scikit-learn, this is used dictionary learning)\n",
    "    - Find the set of sparse components that can optimally reconstruct the data.\n",
    "    $$(U*, V*) = argmin_{U, V} \\frac{1}{2} ||X - UV||_{F}^2 + \\alpha||V||_{1, 1}$$\n",
    "    $$ \\text{subject to } ||U_k||_2 \\leq 1 \\text{, for all } k = {0,...,n_{components}}$$\n",
    "- MiniBatchSparsePCA (scikit-learn, this is used MiniBatchDicionaryLearning)\n",
    "    - Online learning, iterating over batches of the set of features (vertices), for a given number of iterations\n",
    "    - This is faster but less accurate than SparsePCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = ESTIMATOR.fit(masked_cent_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = None #each row represents kth component (should be sparse)\n",
    "W = None #each column represents a weight for kth component\n",
    "if name_method == 'SparsePCA' or name_method == 'MiniBatchSparsePCA':\n",
    "     C = est.components_ #right-hand side V\n",
    "     W = est.transform(masked_cent_X) #left-hand side U\n",
    "# elif name_method == 'DictionaryLearning' or name_method == 'MiniBatchDictionaryLearning':\n",
    "#      _dict = est.components_ #V\n",
    "#      _code = est.transform(masked_cent_X) #U\n",
    "#      C = _code.T\n",
    "#      W = _dict.T\n",
    "MEAN =  ave_neutralmesh_vertices # neutral face mesh (vertex coodinates of neutral face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparsity check\n",
    "# close to 1: Sparse, close to 0: Dense\n",
    "sparsity_level = np.mean(C==0)\n",
    "print(sparsity_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of C (right-handside): {C.shape}\")\n",
    "print(f\"Shape of W (left-handside): {W.shape}\")\n",
    "print(f\"Shape of MEAN (average expressions): {MEAN.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_collection_W = np.max(W, axis=0)\n",
    "std_W = np.std(W, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_collection_W.shape)\n",
    "print(std_W.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visulization of the weight matrix\n",
    "- This is corresponding to the transposed dictionary\n",
    "- Each color represents atom in the dictionary\n",
    "  - This can be interpreted as the projected coordinate on the corresponding axis in the new coordinate system in C\n",
    "- Each row represents K-latent factor vector of the certain tracked mesh data\n",
    "- A vector should be estimated to generate a new expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wx_data = np.arange(0, W.shape[0],1)\n",
    "Wy_data = W\n",
    "plt.plot(Wx_data, Wy_data)\n",
    "plt.xlabel(\"Components\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Coefficient (row) vectors in matrix U\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of the sparse component matrix C\n",
    "- This is corresponding to transposed code\n",
    "- Each color represents new single axis in the new coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.arange(0,C.shape[1], 1)\n",
    "y_data = C.T\n",
    "plt.plot(x_data, y_data[:,:3])\n",
    "plt.xlabel(\"Vertices\")\n",
    "plt.ylabel(\"Displacement\")\n",
    "plt.title(\"Components in matrix V (3 components from first row)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction error of the sparse coded signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_masked_cent_X = W @ C\n",
    "error_rate = np.mean(np.sum((reconstructed_masked_cent_X - masked_cent_X)**2, axis = 1) / np.sum(masked_cent_X**2, axis = 1))\n",
    "print(f\"The reconstruction error of the sparse coded signal relative to the squared euclidean norm of the original signal: {error_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new expressions using sparse components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select D\n",
    "D_Pcs = _n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = []\n",
    "Stds = []\n",
    "for i in range(D_Pcs):\n",
    "    mu,sigma = 0, std_W[i] # mean and standard deviation\n",
    "    Stds.append(sigma)\n",
    "    _noise = np.random.normal(mu, sigma, 1) + 0.5\n",
    "    coefficients.append(abs(_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coefficients)\n",
    "print(len(coefficients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add linear combination of principal components, in which are weighted by coefficients to mean vertex position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newFace_vertices = MEAN\n",
    "for coeff in coefficients:\n",
    "    _item = coeff*C[i]\n",
    "    newFace_vertices = newFace_vertices + _item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newFace_vertices)\n",
    "print(newFace_vertices.shape)\n",
    "print(newFace_vertices.shape[0]/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write a .obj based on obtained vertex positions for visualization\n",
    "- Since the tracked mesh are topologically equivalent, we can easily obtain .obj only by rewriting line for vertex position (starting with 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path configuration\n",
    "sample_path = \"../dataset/multiface/tracked_mesh/sample.obj\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ourput pointclouds (.obj) based on obtained vertex coordinates\n",
    ">>check /dataset/multiface/tracked_mesh/result_point_clouds.obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample obj file should be read first\n",
    "obj = OBJ(sample_path, swapyz=False)\n",
    "obj.write_PointClouds(save_path, newFace_vertices, mesh_name = \"result_point_clouds_SparsePCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ourput mesh (.obj) based on obtained vertex coordinates\n",
    ">>check /dataset/multiface/tracked_mesh/result_mesh.obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample obj file should be read first\n",
    "OBJ.write_OBJfile(reference_obj_file=sample_path, save_path=save_path, vertices=newFace_vertices, name_Exp=\"allPcs_SparsePCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation of each blendshape\n",
    "- Output each blendshape\n",
    "- Compare with average face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Blendshape import Blendshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obtain each blenshape (.obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blendshapes = []\n",
    "\n",
    "if not os.path.exists(os.path.join(save_path, \"First10Pcs_SparsePCA_test\")):\n",
    "    os.mkdir(os.path.join(save_path, \"First10Pcs_SparsePCA_test\"))\n",
    "\n",
    "\n",
    "OBJ.write_OBJfile(reference_obj_file= sample_path, save_path = save_path, vertices=MEAN, name_Exp=\"averageExp\")\n",
    "\n",
    "for i in range(1, 10):\n",
    "    _blendshape = Blendshape(Verts_averageExp=MEAN, PCs=C, Stds = Stds, D = i, save_path=os.path.join(save_path, \"First10Pcs_SparsePCA_test\"), only_specific_pc=True, name_newExp=str(i))\n",
    "    _blendshape.sample_coefficients()\n",
    "    _blendshape.get_newExp()\n",
    "    fname = _blendshape.generate_newExp()\n",
    "    blendshapes.append(_blendshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dump PCs, Stds, MEAN in .pickel for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Blendshape import datastruct_blendshape\n",
    "\n",
    "print(type(MEAN))\n",
    "print(type(C))\n",
    "print(type(Stds))\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_blendshape = datastruct_blendshape(ID = ID, List_exps = list_exps_name, MEAN = MEAN, PCs = C, Stds = Stds)\n",
    "# print(our_blendshape)\n",
    "pickel_fname = 'blendshape_SparsePCA_'+date+'_'+time+'.pkl'\n",
    "# dump datastruct_blendshape\n",
    "dump_pckl(data=our_blendshape, save_root=save_path, pickel_fname=pickel_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(our_blendshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load blendshape from memory (pickel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_memory(path_to_memory=save_path, pickle_fname=pickel_fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dsrf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
